---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: booklore
  labels:
    app: booklore
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: booklore
  template:
    metadata:
      labels:
        app: booklore
    spec:
      tolerations:
        - key: node-role.kubernetes.io/control-plane
          operator: Exists
          effect: NoSchedule
      initContainers:
        - name: restore-config
          image: rclone/rclone:1.73
          securityContext:
            runAsUser: 1000
            runAsGroup: 1000
          command:
            - sh
            - -c
          args:
            - |
              export RCLONE_CONFIG_S3_TYPE=s3
              export RCLONE_CONFIG_S3_PROVIDER=Other
              export RCLONE_CONFIG_S3_ACCESS_KEY_ID=$LITESTREAM_ACCESS_KEY_ID
              export RCLONE_CONFIG_S3_SECRET_ACCESS_KEY=$LITESTREAM_SECRET_ACCESS_KEY
              export RCLONE_CONFIG_S3_ENDPOINT=$LITESTREAM_ENDPOINT
              
              # Marker logic to avoid full re-download
              # Count existing files in images directory
              FILE_COUNT=$(find /app/data/images -type f 2>/dev/null | wc -l)
              MARKER_FILE="/app/data/.restore_marker"
              LAST_COUNT=0
              if [ -f "$MARKER_FILE" ]; then
                LAST_COUNT=$(cat "$MARKER_FILE")
              fi
              
              echo "Found $FILE_COUNT files (Last count: $LAST_COUNT)"
              
              # Logic:
              # 1. If empty or < 10 files -> FULL RESTORE
              # 2. If significant difference (>20% loss) -> SYNC
              # 3. Otherwise -> SKIP (assume healthy PVC)
              
              if [ "$FILE_COUNT" -lt 10 ]; then
                echo "Directory mostly empty. Starting FULL RESTORE..."
                rclone copy s3:$LITESTREAM_BUCKET/config /app/data \
                  --transfers 8 \
                  --exclude "*.log" \
                  --exclude "bookdrop_temp/**" \
                  --exclude "lost+found/**"
              elif [ "$LAST_COUNT" -gt 0 ] && [ "$FILE_COUNT" -lt $(($LAST_COUNT * 80 / 100)) ]; then
                 echo "Significant file loss detected ($FILE_COUNT < $LAST_COUNT). Syncing..."
                 rclone sync s3:$LITESTREAM_BUCKET/config /app/data \
                   --transfers 8 \
                   --exclude "*.log" \
                   --exclude "bookdrop_temp/**" \
                   --exclude "lost+found/**"
              else
                echo "Data present and looks healthy. Skipping heavy restore."
              fi
              
              # Update marker
              NEW_COUNT=$(find /app/data/images -type f 2>/dev/null | wc -l)
              echo "$NEW_COUNT" > "$MARKER_FILE"
          envFrom:
            - secretRef:
                name: booklore-secrets
          resources:
            requests:
              cpu: 10m
              memory: 64Mi
            limits:
              cpu: 100m
              memory: 128Mi
          volumeMounts:
            - name: data
              mountPath: /app/data
      containers:
        - name: booklore
          image: ghcr.io/booklore-app/booklore:v2.0.0
          ports:
            - containerPort: 6060
              name: http
          env:
            - name: APP_USER_ID
              value: "1000"
            - name: APP_GROUP_ID
              value: "1000"
            - name: TZ
              value: Europe/Paris
            - name: BOOKLORE_PORT
              value: "6060"
            - name: DATABASE_URL
              value: jdbc:mariadb://booklore-mariadb:3306/booklore
            - name: DATABASE_USERNAME
              value: booklore
            - name: DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: booklore-secrets
                  key: DB_PASSWORD
          volumeMounts:
            - name: data
              mountPath: /app/data
            - name: books
              mountPath: /books
            - name: bookdrop
              mountPath: /bookdrop
        - name: config-syncer
          image: rclone/rclone:1.73
          securityContext:
            runAsUser: 1000
            runAsGroup: 1000
          command:
            - sh
            - -c
          args:
            - |
              export RCLONE_CONFIG_S3_TYPE=s3
              export RCLONE_CONFIG_S3_PROVIDER=Other
              export RCLONE_CONFIG_S3_ACCESS_KEY_ID=$LITESTREAM_ACCESS_KEY_ID
              export RCLONE_CONFIG_S3_SECRET_ACCESS_KEY=$LITESTREAM_SECRET_ACCESS_KEY
              export RCLONE_CONFIG_S3_ENDPOINT=$LITESTREAM_ENDPOINT
              sync_s3() {
                rclone sync /app/data s3:$LITESTREAM_BUCKET/config \
                  --exclude "*.log" \
                  --exclude "bookdrop_temp/**" \
                  --exclude "lost+found/**";
              }
              while true; do
                sync_s3;
                sleep 60;
              done
          envFrom:
            - secretRef:
                name: booklore-secrets
          resources:
            requests:
              cpu: 10m
              memory: 64Mi
            limits:
              cpu: 100m
              memory: 128Mi
          volumeMounts:
            - name: data
              mountPath: /app/data
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: booklore-config-pvc
        - name: books
          nfs:
            server: 192.168.111.69
            path: /volume3/Content/ebooks
        - name: bookdrop
          nfs:
            server: 192.168.111.69
            path: /volume3/Internal/incoming/ebooks
      securityContext:
        fsGroup: 1000
        fsGroupChangePolicy: OnRootMismatch
