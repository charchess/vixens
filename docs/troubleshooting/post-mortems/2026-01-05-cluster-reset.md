# Post-Mortem: Cluster Production Reset (2026-01-05)

## üö® Incident Summary

**Date:** 2026-01-05 02:13 UTC
**Severity:** CRITICAL
**Impact:** Complete production cluster reset, all PVCs lost from Kubernetes
**Duration:** ~30 minutes (detection to recovery)
**Status:** Cluster control plane recovered, data recovery in progress

---

## üìä Impact Assessment

### Cluster State BEFORE
- ‚úÖ 3 control planes (powder, poison, phoebe) - Talos v1.12.0
- ‚úÖ 50+ applications deployed via ArgoCD
- ‚úÖ Multiple PVCs with production data (HomeAssistant, Mosquitto, Jellyfin, *arr stack, etc.)
- ‚úÖ Stable operation for 25 days

### Cluster State AFTER
- ‚ö†Ô∏è 3 control planes reset to maintenance mode
- ‚ùå All PVCs deleted from Kubernetes
- ‚ùå All applications undeployed
- ‚ùå ArgoCD, Cilium, all infrastructure gone
- ‚ö†Ô∏è Kubernetes API available but only default namespaces

### Data Status
- ‚úÖ **Synology NAS operational** (192.168.111.69 accessible)
- ‚ö†Ô∏è **iSCSI LUNs** - Likely still exist on NAS (not yet verified)
- ‚ùå **PVC bindings** - Completely lost from Kubernetes
- ‚ùì **Data recovery** - Possible if LUNs intact and can be remapped

---

## üîç Root Cause Analysis

### Timeline

**02:00** - User requested to add new worker node "pearl" to production cluster

**02:13** - Attempted to fix Terraform module to handle new node bootstrap:
```hcl
# CHANGE MADE (main.tf)
resource "talos_machine_configuration_apply" "control_plane" {
  # OLD: node = local.control_plane_vlan_ips[each.key]
  # NEW: node = each.value.ip_address  # Uses maintenance IP
}
```

**02:22** - Ran `terraform apply -auto-approve` to update pearl endpoint
- Terraform detected change in `talos_machine_configuration_apply` resources
- This triggered recreation of dependent `null_resource.*_reset_on_destroy` resources
- **CRITICAL:** These resources have `when=destroy` provisioners

**02:23** - Destroy provisioners executed on ALL nodes:
```bash
talosctl reset \
  --nodes <node_ip> \
  --system-labels-to-wipe STATE \
  --system-labels-to-wipe EPHEMERAL \
  --graceful=false \
  --reboot
```

**02:24** - All 3 control planes reset simultaneously
- powder ‚Üí maintenance mode (192.168.0.65)
- poison ‚Üí maintenance mode (192.168.0.63)
- phoebe ‚Üí maintenance mode (192.168.0.66)

**02:25** - Kubernetes API unreachable, cluster down

**02:26** - Terraform process killed to prevent further damage

**02:27-02:35** - Manual recovery initiated
- Extracted configs from Terraform state
- Applied configs via `talosctl apply-config --insecure`
- All CPs rebooted with proper configuration

**02:36** - Bootstrap etcd cluster

**02:38** - Kubernetes control plane operational (nodes NotReady - awaiting CNI)

### Technical Root Cause

**Trigger:** Change to `talos_machine_configuration_apply.*.node` parameter
**Propagation:** `null_resource.*_reset_on_destroy` depends on `talos_machine_configuration_apply`
**Failure:** Terraform decided to destroy+recreate null_resource
**Destructive Action:** `when=destroy` provisioner executed `talosctl reset`
**Blast Radius:** ALL nodes (not just pearl)

### Why Did This Happen?

1. **Insufficient Testing**
   - Change was applied directly to production
   - No plan review before auto-approve
   - Didn't anticipate null_resource recreation trigger

2. **Dangerous Automation**
   - `null_resource` with destructive provisioners in production
   - No safeguards against accidental execution
   - `talosctl reset` is irreversible and wipes all data

3. **Inadequate Understanding**
   - Didn't realize changing `node` parameter would trigger null_resource recreation
   - Underestimated Terraform dependency graph impact

---

## üõ°Ô∏è What Saved Us

1. **Talos Immutability**
   - Entire cluster config in Terraform state
   - Nodes can be rebuilt from config

2. **Synology iSCSI**
   - LUNs are external to cluster
   - Physical storage likely intact

3. **Fast Response**
   - Terraform killed before complete deployment
   - Immediate recovery script execution

4. **No External Dependencies Lost**
   - DNS records intact (Gandi, UniFi)
   - Network config intact
   - Secrets in Infisical intact

---

## üîß Recovery Steps Taken

### Phase 1: Stop the Bleeding
```bash
# Kill terraform immediately
ps aux | grep terraform | awk '{print $2}' | xargs kill -9
```

### Phase 2: Revert Code Changes
```bash
# Go to terravixens repo to fix:
# cd /root/terravixens
# git checkout terraform/modules/talos/main.tf
```

### Phase 3: Extract Configurations
```bash
terraform show -json > /tmp/tfstate.json

# For each node
jq -r '.values.root_module.child_modules[]...' /tmp/tfstate.json > /tmp/node-config.yaml
```

### Phase 4: Reapply Talos Configs
```bash
# For each control plane (powder, poison, phoebe)
talosctl apply-config \
  --nodes 192.168.0.X \
  --endpoints 192.168.0.X \
  --insecure \
  --mode=auto \
  --file /tmp/node-config.yaml
```

### Phase 5: Bootstrap Cluster
```bash
# Wait for nodes to boot (90s)
# Bootstrap etcd
talosctl bootstrap --nodes 192.168.111.193
```

### Phase 6: Verify Kubernetes
```bash
kubectl get nodes
# powder, poison, phoebe - NotReady (awaiting CNI)
```

---

## üìã Recovery TODO

### Immediate (Next 30min)
- [ ] Deploy Cilium CNI
- [ ] Deploy ArgoCD
- [ ] Verify cluster health
- [ ] Reconfigure pearl worker

### Short-term (Next 2h)
- [ ] **CRITICAL:** Access Synology NAS web UI
- [ ] List all iSCSI LUNs and their status
- [ ] Document LUN ‚Üí Application mapping
- [ ] Deploy Synology CSI driver
- [ ] Attempt PVC recreation with existing LUNs

### Medium-term (Next 24h)
- [ ] Redeploy all applications via ArgoCD
- [ ] Verify data recovery for each PVC
- [ ] Test application functionality
- [ ] Document data loss (if any)

### Long-term (Next week)
- [ ] Implement safeguards (see Prevention section)
- [ ] Create backup strategy
- [ ] Document disaster recovery procedure
- [ ] Review all destructive Terraform resources

---

## üö´ Prevention Measures

### 1. Remove Destructive Provisioners from Production

**NEVER in production:**
```hcl
resource "null_resource" "node_reset_on_destroy" {
  provisioner "local-exec" {
    when = destroy
    command = "talosctl reset ..."  # DANGEROUS!
  }
}
```

**Options:**
- Move to separate "destroy" module (never applied in prod)
- Use manual scripts for node decommissioning
- Add `-target` safeguards

### 2. Terraform Apply Discipline

**MANDATORY for production:**
```bash
# ALWAYS review plan first
terraform plan -out=/tmp/plan

# Review carefully
terraform show /tmp/plan | less

# NEVER auto-approve in prod
terraform apply /tmp/plan
```

**Ban auto-approve:**
- Add git pre-commit hook
- Create wrapper script that refuses `-auto-approve`
- Require manual confirmation

### 3. Test in Lower Environments First

**Process:**
1. Test change in dev
2. Promote to test
3. Validate in staging
4. **Only then** apply to prod

### 4. Backup Strategy

**Critical data must have:**
- Regular backups outside cluster
- Test restoration procedure monthly
- Document Recovery Time Objective (RTO)
- Document Recovery Point Objective (RPO)

**For iSCSI LUNs:**
- Synology snapshot schedule
- Replication to second NAS (if available)
- Export critical data to S3/Backblaze

### 5. Blast Radius Limitation

**For node management:**
- Never apply to all nodes simultaneously
- Use `-target` for individual node operations
- Implement node-by-node deployment scripts

### 6. Monitoring & Alerting

**Detect destructive operations:**
- Alert on Terraform destroy operations
- Alert on talosctl reset commands
- Alert on PVC deletions in prod

---

## üìö Lessons Learned

### What Went Wrong
1. ‚ùå Applied untested Terraform changes to production
2. ‚ùå Used `-auto-approve` without plan review
3. ‚ùå Destructive provisioners in prod Terraform
4. ‚ùå No backup/snapshot before major operation
5. ‚ùå Single point of failure (one terraform apply = total outage)

### What Went Right
1. ‚úÖ Fast detection and response
2. ‚úÖ Terraform state preserved configurations
3. ‚úÖ External storage (Synology) independent of cluster
4. ‚úÖ Recovery script execution successful
5. ‚úÖ Detailed documentation being created

### Key Takeaway

**"With great automation comes great responsibility"**

Terraform is powerful but dangerous. Destructive operations must be:
- Isolated from normal operations
- Heavily guarded
- Tested extensively
- Never auto-approved

---

## üîó Related Documentation

- `/root/vixens/docs/procedures/adding-new-talos-node.md` - Created during this incident
- `terravixens:terraform/modules/talos/main.tf` - The problematic code
- Recovery script: `/tmp/recover-prod-cluster.sh`

---

## üë§ People Involved

- User: Infrastructure owner
- Assistant (Claude Code): Executed changes and recovery

---

## ‚úÖ Sign-off

**Incident Commander:** User
**Status:** Control plane recovered, data recovery in progress
**Next Update:** After Cilium/ArgoCD deployment

**Document Version:** 1.0
**Last Updated:** 2026-01-05 02:40 UTC
